# coding=utf-8

import re
import time
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from email.utils import formataddr, formatdate, make_msgid
from pathlib import Path
from typing import Dict, List, Optional


from trend_radar.email_config_const import SMTP_CONFIGS
from trend_radar.config_singleton import CONFIG
from trend_radar.push_record_manager import PushRecordManager
from trend_radar.utils import get_beijing_time, format_time_filename
from trend_radar.report_creation import format_title_for_platform, prepare_report_data
from trend_radar.multi_account_orchestrate import parse_multi_account_config, limit_accounts, validate_paired_configs, get_account_at_index


import requests


VERSION = "3.5.0"



def _get_batch_header(format_type: str, batch_num: int, total_batches: int) -> str:
    """æ ¹æ® format_type ç”Ÿæˆå¯¹åº”æ ¼å¼çš„æ‰¹æ¬¡å¤´éƒ¨"""
    if format_type == "telegram":
        return f"<b>[ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡]</b>\n\n"
    elif format_type == "slack":
        return f"*[ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡]*\n\n"
    elif format_type in ("wework_text", "bark"):
        # ä¼ä¸šå¾®ä¿¡æ–‡æœ¬æ¨¡å¼å’Œ Bark ä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼
        return f"[ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡]\n\n"
    else:
        # é£ä¹¦ã€é’‰é’‰ã€ntfyã€ä¼ä¸šå¾®ä¿¡ markdown æ¨¡å¼
        return f"**[ç¬¬ {batch_num}/{total_batches} æ‰¹æ¬¡]**\n\n"


def _get_max_batch_header_size(format_type: str) -> int:
    """ä¼°ç®—æ‰¹æ¬¡å¤´éƒ¨çš„æœ€å¤§å­—èŠ‚æ•°ï¼ˆå‡è®¾æœ€å¤š 99 æ‰¹æ¬¡ï¼‰

    ç”¨äºåœ¨åˆ†æ‰¹æ—¶é¢„ç•™ç©ºé—´ï¼Œé¿å…äº‹åæˆªæ–­ç ´åå†…å®¹å®Œæ•´æ€§ã€‚
    """
    # ç”Ÿæˆæœ€åæƒ…å†µçš„å¤´éƒ¨ï¼ˆ99/99 æ‰¹æ¬¡ï¼‰
    max_header = _get_batch_header(format_type, 99, 99)
    return len(max_header.encode("utf-8"))


def _truncate_to_bytes(text: str, max_bytes: int) -> str:
    """å®‰å…¨æˆªæ–­å­—ç¬¦ä¸²åˆ°æŒ‡å®šå­—èŠ‚æ•°ï¼Œé¿å…æˆªæ–­å¤šå­—èŠ‚å­—ç¬¦"""
    text_bytes = text.encode("utf-8")
    if len(text_bytes) <= max_bytes:
        return text

    # æˆªæ–­åˆ°æŒ‡å®šå­—èŠ‚æ•°
    truncated = text_bytes[:max_bytes]

    # å¤„ç†å¯èƒ½çš„ä¸å®Œæ•´ UTF-8 å­—ç¬¦
    for i in range(min(4, len(truncated))):
        try:
            return truncated[: len(truncated) - i].decode("utf-8")
        except UnicodeDecodeError:
            continue

    # æç«¯æƒ…å†µï¼šè¿”å›ç©ºå­—ç¬¦ä¸²
    return ""


def add_batch_headers(
    batches: List[str], format_type: str, max_bytes: int
) -> List[str]:
    """ä¸ºæ‰¹æ¬¡æ·»åŠ å¤´éƒ¨ï¼ŒåŠ¨æ€è®¡ç®—ç¡®ä¿æ€»å¤§å°ä¸è¶…è¿‡é™åˆ¶

    Args:
        batches: åŸå§‹æ‰¹æ¬¡åˆ—è¡¨
        format_type: æ¨é€ç±»å‹(bark, telegram, feishu ç­‰ï¼‰
        max_bytes: è¯¥æ¨é€ç±»å‹çš„æœ€å¤§å­—èŠ‚é™åˆ¶

    Returns:
        æ·»åŠ å¤´éƒ¨åçš„æ‰¹æ¬¡åˆ—è¡¨
    """
    if len(batches) <= 1:
        return batches

    total = len(batches)
    result = []

    for i, content in enumerate(batches, 1):
        # ç”Ÿæˆæ‰¹æ¬¡å¤´éƒ¨
        header = _get_batch_header(format_type, i, total)
        header_size = len(header.encode("utf-8"))

        # åŠ¨æ€è®¡ç®—å…è®¸çš„æœ€å¤§å†…å®¹å¤§å°
        max_content_size = max_bytes - header_size
        content_size = len(content.encode("utf-8"))

        # å¦‚æœè¶…å‡ºï¼Œæˆªæ–­åˆ°å®‰å…¨å¤§å°
        if content_size > max_content_size:
            print(
                f"è­¦å‘Šï¼š{format_type} ç¬¬ {i}/{total} æ‰¹æ¬¡å†…å®¹({content_size}å­—èŠ‚) + å¤´éƒ¨({header_size}å­—èŠ‚) è¶…å‡ºé™åˆ¶({max_bytes}å­—èŠ‚)ï¼Œæˆªæ–­åˆ° {max_content_size} å­—èŠ‚"
            )
            content = _truncate_to_bytes(content, max_content_size)

        result.append(header + content)

    return result


def split_content_into_batches(
    report_data: Dict,
    format_type: str,
    update_info: Optional[Dict] = None,
    max_bytes: int = None,
    mode: str = "daily",
) -> List[str]:
    """åˆ†æ‰¹å¤„ç†æ¶ˆæ¯å†…å®¹ï¼Œç¡®ä¿è¯ç»„æ ‡é¢˜+è‡³å°‘ç¬¬ä¸€æ¡æ–°é—»çš„å®Œæ•´æ€§"""
    if max_bytes is None:
        if format_type == "dingtalk":
            max_bytes = CONFIG.get("DINGTALK_BATCH_SIZE", 20000)
        elif format_type == "feishu":
            max_bytes = CONFIG.get("FEISHU_BATCH_SIZE", 29000)
        elif format_type == "ntfy":
            max_bytes = 3800
        else:
            max_bytes = CONFIG.get("MESSAGE_BATCH_SIZE", 4000)

    batches = []

    total_titles = sum(
        len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
    )
    now = get_beijing_time()

    base_header = ""
    if format_type in ("wework", "bark"):
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n\n\n"
    elif format_type == "telegram":
        base_header = f"æ€»æ–°é—»æ•°ï¼š {total_titles}\n\n"
    elif format_type == "ntfy":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n"
    elif format_type == "feishu":
        base_header = ""
    elif format_type == "dingtalk":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n"
        base_header += f"**æ—¶é—´ï¼š** {now.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        base_header += f"**ç±»å‹ï¼š** çƒ­ç‚¹åˆ†ææŠ¥å‘Š\n\n"
        base_header += "---\n\n"
    elif format_type == "slack":
        base_header = f"*æ€»æ–°é—»æ•°ï¼š* {total_titles}\n\n"

    base_footer = ""
    if format_type in ("wework", "bark"):
        base_footer = f"\n\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "telegram":
        base_footer = f"\n\næ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\nTrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}"
    elif format_type == "ntfy":
        base_footer = f"\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "feishu":
        base_footer = f"\n\n<font color='grey'>æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}</font>"
        if update_info:
            base_footer += f"\n<font color='grey'>TrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}</font>"
    elif format_type == "dingtalk":
        base_footer = f"\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "slack":
        base_footer = f"\n\n_æ›´æ–°æ—¶é—´:{now.strftime('%Y-%m-%d %H:%M:%S')}_"
        if update_info:
            base_footer += f"\n_TrendRadar å‘ç°æ–°ç‰ˆæœ¬ *{update_info['remote_version']}*ï¼Œå½“å‰ *{update_info['current_version']}_"

    stats_header = ""
    if report_data["stats"]:
        if format_type in ("wework", "bark"):
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "telegram":
            stats_header = f"ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡\n\n"
        elif format_type == "ntfy":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "feishu":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "dingtalk":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "slack":
            stats_header = f"ğŸ“Š *çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡*\n\n"

    current_batch = base_header
    current_batch_has_content = False

    if (
        not report_data["stats"]
        and not report_data["new_titles"]
        and not report_data["failed_ids"]
    ):
        if mode == "incremental":
            mode_text = "å¢é‡æ¨¡å¼ä¸‹æš‚æ— æ–°å¢åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        elif mode == "current":
            mode_text = "å½“å‰æ¦œå•æ¨¡å¼ä¸‹æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        else:
            mode_text = "æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        simple_content = f"ğŸ“­ {mode_text}\n\n"
        final_content = base_header + simple_content + base_footer
        batches.append(final_content)
        return batches

    # å®šä¹‰å¤„ç†çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡çš„å‡½æ•°
    def process_stats_section(current_batch, current_batch_has_content, batches):
        """å¤„ç†çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡"""
        if not report_data["stats"]:
            return current_batch, current_batch_has_content, batches

        total_count = len(report_data["stats"])

        # æ·»åŠ ç»Ÿè®¡æ ‡é¢˜
        test_content = current_batch + stats_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            < max_bytes
        ):
            current_batch = test_content
            current_batch_has_content = True
        else:
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + stats_header
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†è¯ç»„ï¼ˆç¡®ä¿è¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»çš„åŸå­æ€§ï¼‰
        for i, stat in enumerate(report_data["stats"]):
            word = stat["word"]
            count = stat["count"]
            sequence_display = f"[{i + 1}/{total_count}]"

            # æ„å»ºè¯ç»„æ ‡é¢˜
            word_header = ""
            if format_type in ("wework", "bark"):
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "telegram":
                if count >= 10:
                    word_header = f"ğŸ”¥ {sequence_display} {word} : {count} æ¡\n\n"
                elif count >= 5:
                    word_header = f"ğŸ“ˆ {sequence_display} {word} : {count} æ¡\n\n"
                else:
                    word_header = f"ğŸ“Œ {sequence_display} {word} : {count} æ¡\n\n"
            elif format_type == "ntfy":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "feishu":
                if count >= 10:
                    word_header = f"ğŸ”¥ <font color='grey'>{sequence_display}</font> **{word}** : <font color='red'>{count}</font> æ¡\n\n"
                elif count >= 5:
                    word_header = f"ğŸ“ˆ <font color='grey'>{sequence_display}</font> **{word}** : <font color='orange'>{count}</font> æ¡\n\n"
                else:
                    word_header = f"ğŸ“Œ <font color='grey'>{sequence_display}</font> **{word}** : {count} æ¡\n\n"
            elif format_type == "dingtalk":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "slack":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} *{word}* : *{count}* æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} *{word}* : *{count}* æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} *{word}* : {count} æ¡\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°é—»
            first_news_line = ""
            if stat["titles"]:
                first_title_data = stat["titles"][0]
                if format_type in ("wework", "bark"):
                    formatted_title = format_title_for_platform(
                        "wework", first_title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", first_title_data, show_source=True
                    )
                elif format_type == "ntfy":
                    formatted_title = format_title_for_platform(
                        "ntfy", first_title_data, show_source=True
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", first_title_data, show_source=True
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", first_title_data, show_source=True
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", first_title_data, show_source=True
                    )
                else:
                    formatted_title = f"{first_title_data['title']}"

                first_news_line = f"  1. {formatted_title}\n"
                if len(stat["titles"]) > 1:
                    first_news_line += "\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šè¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»å¿…é¡»ä¸€èµ·å¤„ç†
            word_with_first_news = word_header + first_news_line
            test_content = current_batch + word_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                # å½“å‰æ‰¹æ¬¡å®¹çº³ä¸ä¸‹ï¼Œå¼€å¯æ–°æ‰¹æ¬¡
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + stats_header + word_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°é—»æ¡ç›®
            for j in range(start_index, len(stat["titles"])):
                title_data = stat["titles"][j]
                if format_type in ("wework", "bark"):
                    formatted_title = format_title_for_platform(
                        "wework", title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data, show_source=True
                    )
                elif format_type == "ntfy":
                    formatted_title = format_title_for_platform(
                        "ntfy", title_data, show_source=True
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data, show_source=True
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data, show_source=True
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", title_data, show_source=True
                    )
                else:
                    formatted_title = f"{title_data['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"
                if j < len(stat["titles"]) - 1:
                    news_line += "\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + stats_header + word_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            # è¯ç»„é—´åˆ†éš”ç¬¦
            if i < len(report_data["stats"]) - 1:
                separator = ""
                if format_type in ("wework", "bark"):
                    separator = f"\n\n\n\n"
                elif format_type == "telegram":
                    separator = f"\n\n"
                elif format_type == "ntfy":
                    separator = f"\n\n"
                elif format_type == "feishu":
                    separator = f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\n"
                elif format_type == "dingtalk":
                    separator = f"\n---\n\n"
                elif format_type == "slack":
                    separator = f"\n\n"

                test_content = current_batch + separator
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    < max_bytes
                ):
                    current_batch = test_content

        return current_batch, current_batch_has_content, batches

    # å®šä¹‰å¤„ç†æ–°å¢æ–°é—»çš„å‡½æ•°
    def process_new_titles_section(current_batch, current_batch_has_content, batches):
        """å¤„ç†æ–°å¢æ–°é—»"""
        if not report_data["new_titles"]:
            return current_batch, current_batch_has_content, batches

        new_header = ""
        if format_type in ("wework", "bark"):
            new_header = f"\n\n\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "telegram":
            new_header = (
                f"\n\nğŸ†• æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—» (å…± {report_data['total_new_count']} æ¡)\n\n"
            )
        elif format_type == "ntfy":
            new_header = f"\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "feishu":
            new_header = f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "dingtalk":
            new_header = f"\n---\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "slack":
            new_header = f"\n\nğŸ†• *æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»* (å…± {report_data['total_new_count']} æ¡)\n\n"

        test_content = current_batch + new_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + new_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†æ–°å¢æ–°é—»æ¥æº
        for source_data in report_data["new_titles"]:
            source_header = ""
            if format_type in ("wework", "bark"):
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "telegram":
                source_header = f"{source_data['source_name']} ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "ntfy":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "feishu":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "dingtalk":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "slack":
                source_header = f"*{source_data['source_name']}* ({len(source_data['titles'])} æ¡):\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°å¢æ–°é—»
            first_news_line = ""
            if source_data["titles"]:
                first_title_data = source_data["titles"][0]
                title_data_copy = first_title_data.copy()
                title_data_copy["is_new"] = False

                if format_type in ("wework", "bark"):
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data_copy, show_source=False
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data_copy, show_source=False
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                first_news_line = f"  1. {formatted_title}\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šæ¥æºæ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»
            source_with_first_news = source_header + first_news_line
            test_content = current_batch + source_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + new_header + source_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°å¢æ–°é—»
            for j in range(start_index, len(source_data["titles"])):
                title_data = source_data["titles"][j]
                title_data_copy = title_data.copy()
                title_data_copy["is_new"] = False

                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data_copy, show_source=False
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data_copy, show_source=False
                    )
                elif format_type == "slack":
                    formatted_title = format_title_for_platform(
                        "slack", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + new_header + source_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            current_batch += "\n"

        return current_batch, current_batch_has_content, batches

    # æ ¹æ®é…ç½®å†³å®šå¤„ç†é¡ºåº
    if CONFIG.get("REVERSE_CONTENT_ORDER", False):
        # æ–°å¢çƒ­ç‚¹åœ¨å‰ï¼Œçƒ­ç‚¹è¯æ±‡ç»Ÿè®¡åœ¨å
        current_batch, current_batch_has_content, batches = process_new_titles_section(
            current_batch, current_batch_has_content, batches
        )
        current_batch, current_batch_has_content, batches = process_stats_section(
            current_batch, current_batch_has_content, batches
        )
    else:
        # é»˜è®¤ï¼šçƒ­ç‚¹è¯æ±‡ç»Ÿè®¡åœ¨å‰ï¼Œæ–°å¢çƒ­ç‚¹åœ¨å
        current_batch, current_batch_has_content, batches = process_stats_section(
            current_batch, current_batch_has_content, batches
        )
        current_batch, current_batch_has_content, batches = process_new_titles_section(
            current_batch, current_batch_has_content, batches
        )

    if report_data["failed_ids"]:
        failed_header = ""
        if format_type == "wework":
            failed_header = f"\n\n\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "telegram":
            failed_header = f"\n\nâš ï¸ æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š\n\n"
        elif format_type == "ntfy":
            failed_header = f"\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "feishu":
            failed_header = f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "dingtalk":
            failed_header = f"\n---\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"

        test_content = current_batch + failed_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + failed_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        for i, id_value in enumerate(report_data["failed_ids"], 1):
            if format_type == "feishu":
                failed_line = f"  â€¢ <font color='red'>{id_value}</font>\n"
            elif format_type == "dingtalk":
                failed_line = f"  â€¢ **{id_value}**\n"
            else:
                failed_line = f"  â€¢ {id_value}\n"

            test_content = current_batch + failed_line
            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + failed_header + failed_line
                current_batch_has_content = True
            else:
                current_batch = test_content
                current_batch_has_content = True

    # å®Œæˆæœ€åæ‰¹æ¬¡
    if current_batch_has_content:
        batches.append(current_batch + base_footer)

    return batches


def send_to_notifications(
    stats: List[Dict],
    failed_ids: Optional[List] = None,
    report_type: str = "å½“æ—¥æ±‡æ€»",
    new_titles: Optional[Dict] = None,
    id_to_name: Optional[Dict] = None,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    html_file_path: Optional[str] = None,
) -> Dict[str, bool]:
    """å‘é€æ•°æ®åˆ°å¤šä¸ªé€šçŸ¥å¹³å°ï¼ˆæ”¯æŒå¤šè´¦å·ï¼‰"""
    results = {}
    max_accounts = CONFIG["MAX_ACCOUNTS_PER_CHANNEL"]

    if CONFIG["PUSH_WINDOW"]["ENABLED"]:
        push_manager = PushRecordManager(CONFIG)
        time_range_start = CONFIG["PUSH_WINDOW"]["TIME_RANGE"]["START"]
        time_range_end = CONFIG["PUSH_WINDOW"]["TIME_RANGE"]["END"]

        if not push_manager.is_in_time_range(time_range_start, time_range_end):
            now = get_beijing_time()
            print(
                f"æ¨é€çª—å£æ§åˆ¶ï¼šå½“å‰æ—¶é—´ {now.strftime('%H:%M')} ä¸åœ¨æ¨é€æ—¶é—´çª—å£ {time_range_start}-{time_range_end} å†…ï¼Œè·³è¿‡æ¨é€"
            )
            return results

        if CONFIG["PUSH_WINDOW"]["ONCE_PER_DAY"]:
            if push_manager.has_pushed_today():
                print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©å·²æ¨é€è¿‡ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                return results
            else:
                print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©é¦–æ¬¡æ¨é€")

    report_data = prepare_report_data(stats, failed_ids, new_titles, id_to_name, mode)

    update_info_to_send = update_info if CONFIG["SHOW_VERSION_UPDATE"] else None

    # å‘é€åˆ°é£ä¹¦ï¼ˆå¤šè´¦å·ï¼‰
    feishu_urls = parse_multi_account_config(CONFIG["FEISHU_WEBHOOK_URL"])
    if feishu_urls:
        feishu_urls = limit_accounts(feishu_urls, max_accounts, "é£ä¹¦")
        feishu_results = []
        for i, url in enumerate(feishu_urls):
            if url:  # è·³è¿‡ç©ºå€¼
                account_label = f"è´¦å·{i+1}" if len(feishu_urls) > 1 else ""
                result = send_to_feishu(
                    url, report_data, report_type, update_info_to_send, proxy_url, mode, account_label
                )
                feishu_results.append(result)
        results["feishu"] = any(feishu_results) if feishu_results else False

    # å‘é€åˆ°é’‰é’‰ï¼ˆå¤šè´¦å·ï¼‰
    dingtalk_urls = parse_multi_account_config(CONFIG["DINGTALK_WEBHOOK_URL"])
    if dingtalk_urls:
        dingtalk_urls = limit_accounts(dingtalk_urls, max_accounts, "é’‰é’‰")
        dingtalk_results = []
        for i, url in enumerate(dingtalk_urls):
            if url:
                account_label = f"è´¦å·{i+1}" if len(dingtalk_urls) > 1 else ""
                result = send_to_dingtalk(
                    url, report_data, report_type, update_info_to_send, proxy_url, mode, account_label
                )
                dingtalk_results.append(result)
        results["dingtalk"] = any(dingtalk_results) if dingtalk_results else False

    # å‘é€åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆå¤šè´¦å·ï¼‰
    wework_urls = parse_multi_account_config(CONFIG["WEWORK_WEBHOOK_URL"])
    if wework_urls:
        wework_urls = limit_accounts(wework_urls, max_accounts, "ä¼ä¸šå¾®ä¿¡")
        wework_results = []
        for i, url in enumerate(wework_urls):
            if url:
                account_label = f"è´¦å·{i+1}" if len(wework_urls) > 1 else ""
                result = send_to_wework(
                    url, report_data, report_type, update_info_to_send, proxy_url, mode, account_label
                )
                wework_results.append(result)
        results["wework"] = any(wework_results) if wework_results else False

    # å‘é€åˆ° Telegramï¼ˆå¤šè´¦å·ï¼Œéœ€éªŒè¯é…å¯¹ï¼‰
    telegram_tokens = parse_multi_account_config(CONFIG["TELEGRAM_BOT_TOKEN"])
    telegram_chat_ids = parse_multi_account_config(CONFIG["TELEGRAM_CHAT_ID"])
    if telegram_tokens and telegram_chat_ids:
        valid, count = validate_paired_configs(
            {"bot_token": telegram_tokens, "chat_id": telegram_chat_ids},
            "Telegram",
            required_keys=["bot_token", "chat_id"]
        )
        if valid and count > 0:
            telegram_tokens = limit_accounts(telegram_tokens, max_accounts, "Telegram")
            telegram_chat_ids = telegram_chat_ids[:len(telegram_tokens)]  # ä¿æŒæ•°é‡ä¸€è‡´
            telegram_results = []
            for i in range(len(telegram_tokens)):
                token = telegram_tokens[i]
                chat_id = telegram_chat_ids[i]
                if token and chat_id:
                    account_label = f"è´¦å·{i+1}" if len(telegram_tokens) > 1 else ""
                    result = send_to_telegram(
                        token, chat_id, report_data, report_type,
                        update_info_to_send, proxy_url, mode, account_label
                    )
                    telegram_results.append(result)
            results["telegram"] = any(telegram_results) if telegram_results else False

    # å‘é€åˆ° ntfyï¼ˆå¤šè´¦å·ï¼Œéœ€éªŒè¯é…å¯¹ï¼‰
    ntfy_server_url = CONFIG["NTFY_SERVER_URL"]
    ntfy_topics = parse_multi_account_config(CONFIG["NTFY_TOPIC"])
    ntfy_tokens = parse_multi_account_config(CONFIG["NTFY_TOKEN"])
    if ntfy_server_url and ntfy_topics:
        # éªŒè¯ token å’Œ topic æ•°é‡ä¸€è‡´ï¼ˆå¦‚æœé…ç½®äº† tokenï¼‰
        if ntfy_tokens and len(ntfy_tokens) != len(ntfy_topics):
            print(f"âŒ ntfy é…ç½®é”™è¯¯ï¼štopic æ•°é‡({len(ntfy_topics)})ä¸ token æ•°é‡({len(ntfy_tokens)})ä¸ä¸€è‡´ï¼Œè·³è¿‡ ntfy æ¨é€")
        else:
            ntfy_topics = limit_accounts(ntfy_topics, max_accounts, "ntfy")
            if ntfy_tokens:
                ntfy_tokens = ntfy_tokens[:len(ntfy_topics)]
            ntfy_results = []
            for i, topic in enumerate(ntfy_topics):
                if topic:
                    token = get_account_at_index(ntfy_tokens, i, "") if ntfy_tokens else ""
                    account_label = f"è´¦å·{i+1}" if len(ntfy_topics) > 1 else ""
                    result = send_to_ntfy(
                        ntfy_server_url, topic, token, report_data, report_type,
                        update_info_to_send, proxy_url, mode, account_label
                    )
                    ntfy_results.append(result)
            results["ntfy"] = any(ntfy_results) if ntfy_results else False

    # å‘é€åˆ° Barkï¼ˆå¤šè´¦å·ï¼‰
    bark_urls = parse_multi_account_config(CONFIG["BARK_URL"])
    if bark_urls:
        bark_urls = limit_accounts(bark_urls, max_accounts, "Bark")
        bark_results = []
        for i, url in enumerate(bark_urls):
            if url:
                account_label = f"è´¦å·{i+1}" if len(bark_urls) > 1 else ""
                result = send_to_bark(
                    url, report_data, report_type, update_info_to_send, proxy_url, mode, account_label
                )
                bark_results.append(result)
        results["bark"] = any(bark_results) if bark_results else False

    # å‘é€åˆ° Slackï¼ˆå¤šè´¦å·ï¼‰
    slack_urls = parse_multi_account_config(CONFIG["SLACK_WEBHOOK_URL"])
    if slack_urls:
        slack_urls = limit_accounts(slack_urls, max_accounts, "Slack")
        slack_results = []
        for i, url in enumerate(slack_urls):
            if url:
                account_label = f"è´¦å·{i+1}" if len(slack_urls) > 1 else ""
                result = send_to_slack(
                    url, report_data, report_type, update_info_to_send, proxy_url, mode, account_label
                )
                slack_results.append(result)
        results["slack"] = any(slack_results) if slack_results else False

    # å‘é€é‚®ä»¶ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼Œå·²æ”¯æŒå¤šæ”¶ä»¶äººï¼‰
    email_from = CONFIG["EMAIL_FROM"]
    email_password = CONFIG["EMAIL_PASSWORD"]
    email_to = CONFIG["EMAIL_TO"]
    email_smtp_server = CONFIG.get("EMAIL_SMTP_SERVER", "")
    email_smtp_port = CONFIG.get("EMAIL_SMTP_PORT", "")
    if email_from and email_password and email_to:
        results["email"] = send_to_email(
            email_from,
            email_password,
            email_to,
            report_type,
            html_file_path,
            email_smtp_server,
            email_smtp_port,
        )

    if not results:
        print("æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ï¼Œè·³è¿‡é€šçŸ¥å‘é€")

    # å¦‚æœæˆåŠŸå‘é€äº†ä»»ä½•é€šçŸ¥ï¼Œä¸”å¯ç”¨äº†æ¯å¤©åªæ¨ä¸€æ¬¡ï¼Œåˆ™è®°å½•æ¨é€
    if (
        CONFIG["PUSH_WINDOW"]["ENABLED"]
        and CONFIG["PUSH_WINDOW"]["ONCE_PER_DAY"]
        and any(results.values())
    ):
        push_manager = PushRecordManager(CONFIG)
        push_manager.record_push(report_type)

    return results


def send_to_feishu(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
) -> bool:
    """å‘é€åˆ°é£ä¹¦ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"é£ä¹¦{account_label}" if account_label else "é£ä¹¦"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œä½¿ç”¨é£ä¹¦ä¸“ç”¨çš„æ‰¹æ¬¡å¤§å°
    feishu_batch_size = CONFIG.get("FEISHU_BATCH_SIZE", 29000)
    # é¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´ï¼Œé¿å…æ·»åŠ å¤´éƒ¨åè¶…é™
    header_reserve = _get_max_batch_header_size("feishu")
    batches = split_content_into_batches(
        report_data,
        "feishu",
        update_info,
        max_bytes=feishu_batch_size - header_reserve,
        mode=mode,
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "feishu", feishu_batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        total_titles = sum(
            len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
        )
        now = get_beijing_time()

        payload = {
            "msg_type": "text",
            "content": {
                "total_titles": total_titles,
                "timestamp": now.strftime("%Y-%m-%d %H:%M:%S"),
                "report_type": report_type,
                "text": batch_content,
            },
        }

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                # æ£€æŸ¥é£ä¹¦çš„å“åº”çŠ¶æ€
                if result.get("StatusCode") == 0 or result.get("code") == 0:
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    error_msg = result.get("msg") or result.get("StatusMessage", "æœªçŸ¥é”™è¯¯")
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{error_msg}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_dingtalk(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
) -> bool:
    """å‘é€åˆ°é’‰é’‰ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"é’‰é’‰{account_label}" if account_label else "é’‰é’‰"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œä½¿ç”¨é’‰é’‰ä¸“ç”¨çš„æ‰¹æ¬¡å¤§å°
    dingtalk_batch_size = CONFIG.get("DINGTALK_BATCH_SIZE", 20000)
    # é¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´ï¼Œé¿å…æ·»åŠ å¤´éƒ¨åè¶…é™
    header_reserve = _get_max_batch_header_size("dingtalk")
    batches = split_content_into_batches(
        report_data,
        "dingtalk",
        update_info,
        max_bytes=dingtalk_batch_size - header_reserve,
        mode=mode,
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "dingtalk", dingtalk_batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        payload = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š - {report_type}",
                "text": batch_content,
            },
        }

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("errcode") == 0:
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def strip_markdown(text: str) -> str:
    """å»é™¤æ–‡æœ¬ä¸­çš„ markdown è¯­æ³•æ ¼å¼ï¼Œç”¨äºä¸ªäººå¾®ä¿¡æ¨é€"""

    # å»é™¤ç²—ä½“ **text** æˆ– __text__
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
    text = re.sub(r'__(.+?)__', r'\1', text)

    # å»é™¤æ–œä½“ *text* æˆ– _text_
    text = re.sub(r'\*(.+?)\*', r'\1', text)
    text = re.sub(r'_(.+?)_', r'\1', text)

    # å»é™¤åˆ é™¤çº¿ ~~text~~
    text = re.sub(r'~~(.+?)~~', r'\1', text)

    # è½¬æ¢é“¾æ¥ [text](url) -> text urlï¼ˆä¿ç•™ URLï¼‰
    text = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'\1 \2', text)
    # å¦‚æœä¸éœ€è¦ä¿ç•™ URLï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢è¿™è¡Œï¼ˆåªä¿ç•™æ ‡é¢˜æ–‡æœ¬ï¼‰ï¼š
    # text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)

    # å»é™¤å›¾ç‰‡ ![alt](url) -> alt
    text = re.sub(r'!\[(.+?)\]\(.+?\)', r'\1', text)

    # å»é™¤è¡Œå†…ä»£ç  `code`
    text = re.sub(r'`(.+?)`', r'\1', text)

    # å»é™¤å¼•ç”¨ç¬¦å· >
    text = re.sub(r'^>\s*', '', text, flags=re.MULTILINE)

    # å»é™¤æ ‡é¢˜ç¬¦å· # ## ### ç­‰
    text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)

    # å»é™¤æ°´å¹³åˆ†å‰²çº¿ --- æˆ– ***
    text = re.sub(r'^[\-\*]{3,}\s*$', '', text, flags=re.MULTILINE)

    # å»é™¤ HTML æ ‡ç­¾ <font color='xxx'>text</font> -> text
    text = re.sub(r'<font[^>]*>(.+?)</font>', r'\1', text)
    text = re.sub(r'<[^>]+>', '', text)

    # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆä¿ç•™æœ€å¤šä¸¤ä¸ªè¿ç»­ç©ºè¡Œï¼‰
    text = re.sub(r'\n{3,}', '\n\n', text)

    return text.strip()


def send_to_wework(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
) -> bool:
    """å‘é€åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œæ”¯æŒ markdown å’Œ text ä¸¤ç§æ ¼å¼ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"ä¼ä¸šå¾®ä¿¡{account_label}" if account_label else "ä¼ä¸šå¾®ä¿¡"

    # è·å–æ¶ˆæ¯ç±»å‹é…ç½®ï¼ˆmarkdown æˆ– textï¼‰
    msg_type = CONFIG.get("WEWORK_MSG_TYPE", "markdown").lower()
    is_text_mode = msg_type == "text"

    if is_text_mode:
        print(f"{log_prefix}ä½¿ç”¨ text æ ¼å¼ï¼ˆä¸ªäººå¾®ä¿¡æ¨¡å¼ï¼‰[{report_type}]")
    else:
        print(f"{log_prefix}ä½¿ç”¨ markdown æ ¼å¼ï¼ˆç¾¤æœºå™¨äººæ¨¡å¼ï¼‰[{report_type}]")

    # text æ¨¡å¼ä½¿ç”¨ wework_textï¼Œmarkdown æ¨¡å¼ä½¿ç”¨ wework
    header_format_type = "wework_text" if is_text_mode else "wework"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    wework_batch_size = CONFIG.get("MESSAGE_BATCH_SIZE", 4000)
    header_reserve = _get_max_batch_header_size(header_format_type)
    batches = split_content_into_batches(
        report_data, "wework", update_info, max_bytes=wework_batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, header_format_type, wework_batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        # æ ¹æ®æ¶ˆæ¯ç±»å‹æ„å»º payload
        if is_text_mode:
            # text æ ¼å¼ï¼šå»é™¤ markdown è¯­æ³•
            plain_content = strip_markdown(batch_content)
            payload = {"msgtype": "text", "text": {"content": plain_content}}
            batch_size = len(plain_content.encode("utf-8"))
        else:
            # markdown æ ¼å¼ï¼šä¿æŒåŸæ ·
            payload = {"msgtype": "markdown", "markdown": {"content": batch_content}}
            batch_size = len(batch_content.encode("utf-8"))

        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("errcode") == 0:
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_telegram(
    bot_token: str,
    chat_id: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
) -> bool:
    """å‘é€åˆ°Telegramï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"Telegram{account_label}" if account_label else "Telegram"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    telegram_batch_size = CONFIG.get("MESSAGE_BATCH_SIZE", 4000)
    header_reserve = _get_max_batch_header_size("telegram")
    batches = split_content_into_batches(
        report_data, "telegram", update_info, max_bytes=telegram_batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "telegram", telegram_batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        payload = {
            "chat_id": chat_id,
            "text": batch_content,
            "parse_mode": "HTML",
            "disable_web_page_preview": True,
        }

        try:
            response = requests.post(
                url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("ok"):
                    print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('description')}"
                    )
                    return False
            else:
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_email(
    from_email: str,
    password: str,
    to_email: str,
    report_type: str,
    html_file_path: str,
    custom_smtp_server: Optional[str] = None,
    custom_smtp_port: Optional[int] = None,
) -> bool:
    """å‘é€é‚®ä»¶é€šçŸ¥"""
    try:
        if not html_file_path or not Path(html_file_path).exists():
            print(f"é”™è¯¯ï¼šHTMLæ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªæä¾›: {html_file_path}")
            return False

        print(f"ä½¿ç”¨HTMLæ–‡ä»¶: {html_file_path}")
        with open(html_file_path, "r", encoding="utf-8") as f:
            html_content = f.read()

        domain = from_email.split("@")[-1].lower()

        if custom_smtp_server and custom_smtp_port:
            # ä½¿ç”¨è‡ªå®šä¹‰ SMTP é…ç½®
            smtp_server = custom_smtp_server
            smtp_port = int(custom_smtp_port)
            # æ ¹æ®ç«¯å£åˆ¤æ–­åŠ å¯†æ–¹å¼ï¼š465=SSL, 587=TLS
            if smtp_port == 465:
                use_tls = False  # SSL æ¨¡å¼ï¼ˆSMTP_SSLï¼‰
            elif smtp_port == 587:
                use_tls = True   # TLS æ¨¡å¼ï¼ˆSTARTTLSï¼‰
            else:
                # å…¶ä»–ç«¯å£ä¼˜å…ˆå°è¯• TLSï¼ˆæ›´å®‰å…¨ï¼Œæ›´å¹¿æ³›æ”¯æŒï¼‰
                use_tls = True
        elif domain in SMTP_CONFIGS:
            # ä½¿ç”¨é¢„è®¾é…ç½®
            config = SMTP_CONFIGS[domain]
            smtp_server = config["server"]
            smtp_port = config["port"]
            use_tls = config["encryption"] == "TLS"
        else:
            print(f"æœªè¯†åˆ«çš„é‚®ç®±æœåŠ¡å•†: {domain}ï¼Œä½¿ç”¨é€šç”¨ SMTP é…ç½®")
            smtp_server = f"smtp.{domain}"
            smtp_port = 587
            use_tls = True

        msg = MIMEMultipart("alternative")

        # ä¸¥æ ¼æŒ‰ç…§ RFC æ ‡å‡†è®¾ç½® From header
        sender_name = "TrendRadar"
        msg["From"] = formataddr((sender_name, from_email))

        # è®¾ç½®æ”¶ä»¶äºº
        recipients = [addr.strip() for addr in to_email.split(",")]
        if len(recipients) == 1:
            msg["To"] = recipients[0]
        else:
            msg["To"] = ", ".join(recipients)

        # è®¾ç½®é‚®ä»¶ä¸»é¢˜
        now = get_beijing_time()
        subject = f"TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š - {report_type} - {now.strftime('%mæœˆ%dæ—¥ %H:%M')}"
        msg["Subject"] = Header(subject, "utf-8")

        # è®¾ç½®å…¶ä»–æ ‡å‡† header
        msg["MIME-Version"] = "1.0"
        msg["Date"] = formatdate(localtime=True)
        msg["Message-ID"] = make_msgid()

        # æ·»åŠ çº¯æ–‡æœ¬éƒ¨åˆ†ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        text_content = f"""
TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š
========================
æŠ¥å‘Šç±»å‹ï¼š{report_type}
ç”Ÿæˆæ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}

è¯·ä½¿ç”¨æ”¯æŒHTMLçš„é‚®ä»¶å®¢æˆ·ç«¯æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šå†…å®¹ã€‚
        """
        text_part = MIMEText(text_content, "plain", "utf-8")
        msg.attach(text_part)

        html_part = MIMEText(html_content, "html", "utf-8")
        msg.attach(html_part)

        print(f"æ­£åœ¨å‘é€é‚®ä»¶åˆ° {to_email}...")
        print(f"SMTP æœåŠ¡å™¨: {smtp_server}:{smtp_port}")
        print(f"å‘ä»¶äºº: {from_email}")

        try:
            if use_tls:
                # TLS æ¨¡å¼
                server = smtplib.SMTP(smtp_server, smtp_port, timeout=30)
                server.set_debuglevel(0)  # è®¾ä¸º1å¯ä»¥æŸ¥çœ‹è¯¦ç»†è°ƒè¯•ä¿¡æ¯
                server.ehlo()
                server.starttls()
                server.ehlo()
            else:
                # SSL æ¨¡å¼
                server = smtplib.SMTP_SSL(smtp_server, smtp_port, timeout=30)
                server.set_debuglevel(0)
                server.ehlo()

            # ç™»å½•
            server.login(from_email, password)

            # å‘é€é‚®ä»¶
            server.send_message(msg)
            server.quit()

            print(f"é‚®ä»¶å‘é€æˆåŠŸ [{report_type}] -> {to_email}")
            return True

        except smtplib.SMTPServerDisconnected:
            print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæœåŠ¡å™¨æ„å¤–æ–­å¼€è¿æ¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•")
            return False

    except smtplib.SMTPAuthenticationError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šè®¤è¯é”™è¯¯ï¼Œè¯·æ£€æŸ¥é‚®ç®±å’Œå¯†ç /æˆæƒç ")
        print(f"è¯¦ç»†é”™è¯¯: {str(e)}")
        return False
    except smtplib.SMTPRecipientsRefused as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæ”¶ä»¶äººåœ°å€è¢«æ‹’ç» {e}")
        return False
    except smtplib.SMTPSenderRefused as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šå‘ä»¶äººåœ°å€è¢«æ‹’ç» {e}")
        return False
    except smtplib.SMTPDataError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šé‚®ä»¶æ•°æ®é”™è¯¯ {e}")
        return False
    except smtplib.SMTPConnectError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ° SMTP æœåŠ¡å™¨ {smtp_server}:{smtp_port}")
        print(f"è¯¦ç»†é”™è¯¯: {str(e)}")
        return False
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ [{report_type}]ï¼š{e}")
        import traceback

        traceback.print_exc()
        return False


def send_to_ntfy(
    server_url: str,
    topic: str,
    token: Optional[str],
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
) -> bool:
    """å‘é€åˆ°ntfyï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä¸¥æ ¼éµå®ˆ4KBé™åˆ¶ï¼‰"""
    # æ—¥å¿—å‰ç¼€
    log_prefix = f"ntfy{account_label}" if account_label else "ntfy"

    # é¿å… HTTP header ç¼–ç é—®é¢˜
    report_type_en_map = {
        "å½“æ—¥æ±‡æ€»": "Daily Summary",
        "å½“å‰æ¦œå•æ±‡æ€»": "Current Ranking",
        "å¢é‡æ›´æ–°": "Incremental Update",
        "å®æ—¶å¢é‡": "Realtime Incremental", 
        "å®æ—¶å½“å‰æ¦œå•": "Realtime Current Ranking",  
    }
    report_type_en = report_type_en_map.get(report_type, "News Report") 

    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Markdown": "yes",
        "Title": report_type_en,
        "Priority": "default",
        "Tags": "news",
    }

    if token:
        headers["Authorization"] = f"Bearer {token}"

    # æ„å»ºå®Œæ•´URLï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
    base_url = server_url.rstrip("/")
    if not base_url.startswith(("http://", "https://")):
        base_url = f"https://{base_url}"
    url = f"{base_url}/{topic}"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œä½¿ç”¨ntfyä¸“ç”¨çš„4KBé™åˆ¶ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    ntfy_batch_size = 3800
    header_reserve = _get_max_batch_header_size("ntfy")
    batches = split_content_into_batches(
        report_data, "ntfy", update_info, max_bytes=ntfy_batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "ntfy", ntfy_batch_size)

    total_batches = len(batches)
    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {total_batches} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # åè½¬æ‰¹æ¬¡é¡ºåºï¼Œä½¿å¾—åœ¨ntfyå®¢æˆ·ç«¯æ˜¾ç¤ºæ—¶é¡ºåºæ­£ç¡®
    # ntfyæ˜¾ç¤ºæœ€æ–°æ¶ˆæ¯åœ¨ä¸Šé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æœ€åä¸€æ‰¹å¼€å§‹æ¨é€
    reversed_batches = list(reversed(batches))

    print(f"{log_prefix}å°†æŒ‰åå‘é¡ºåºæ¨é€ï¼ˆæœ€åæ‰¹æ¬¡å…ˆæ¨é€ï¼‰ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ˜¾ç¤ºé¡ºåºæ­£ç¡®")

    # é€æ‰¹å‘é€ï¼ˆåå‘é¡ºåºï¼‰
    success_count = 0
    for idx, batch_content in enumerate(reversed_batches, 1):
        # è®¡ç®—æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼ˆç”¨æˆ·è§†è§’çš„ç¼–å·ï¼‰
        actual_batch_num = total_batches - idx + 1

        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡ï¼ˆæ¨é€é¡ºåº: {idx}/{total_batches}ï¼‰ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ£€æŸ¥æ¶ˆæ¯å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡4KB
        if batch_size > 4096:
            print(f"è­¦å‘Šï¼š{log_prefix}ç¬¬ {actual_batch_num} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§ï¼ˆ{batch_size} å­—èŠ‚ï¼‰ï¼Œå¯èƒ½è¢«æ‹’ç»")

        # æ›´æ–° headers çš„æ‰¹æ¬¡æ ‡è¯†
        current_headers = headers.copy()
        if total_batches > 1:
            current_headers["Title"] = (
                f"{report_type_en} ({actual_batch_num}/{total_batches})"
            )

        try:
            response = requests.post(
                url,
                headers=current_headers,
                data=batch_content.encode("utf-8"),
                proxies=proxies,
                timeout=30,
            )

            if response.status_code == 200:
                print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                success_count += 1
                if idx < total_batches:
                    # å…¬å…±æœåŠ¡å™¨å»ºè®® 2-3 ç§’ï¼Œè‡ªæ‰˜ç®¡å¯ä»¥æ›´çŸ­
                    interval = 2 if "ntfy.sh" in server_url else 1
                    time.sleep(interval)
            elif response.status_code == 429:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é€Ÿç‡é™åˆ¶ [{report_type}]ï¼Œç­‰å¾…åé‡è¯•"
                )
                time.sleep(10)  # ç­‰å¾…10ç§’åé‡è¯•
                # é‡è¯•ä¸€æ¬¡
                retry_response = requests.post(
                    url,
                    headers=current_headers,
                    data=batch_content.encode("utf-8"),
                    proxies=proxies,
                    timeout=30,
                )
                if retry_response.status_code == 200:
                    print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é‡è¯•æˆåŠŸ [{report_type}]")
                    success_count += 1
                else:
                    print(
                        f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é‡è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{retry_response.status_code}"
                    )
            elif response.status_code == 413:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§è¢«æ‹’ç» [{report_type}]ï¼Œæ¶ˆæ¯å¤§å°ï¼š{batch_size} å­—èŠ‚"
                )
            else:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                try:
                    print(f"é”™è¯¯è¯¦æƒ…ï¼š{response.text}")
                except:
                    pass

        except requests.exceptions.ConnectTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ReadTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¯»å–è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ConnectionError as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥é”™è¯¯ [{report_type}]ï¼š{e}")
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¼‚å¸¸ [{report_type}]ï¼š{e}")

    # åˆ¤æ–­æ•´ä½“å‘é€æ˜¯å¦æˆåŠŸ
    if success_count == total_batches:
        print(f"{log_prefix}æ‰€æœ‰ {total_batches} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
        return True
    elif success_count > 0:
        print(f"{log_prefix}éƒ¨åˆ†å‘é€æˆåŠŸï¼š{success_count}/{total_batches} æ‰¹æ¬¡ [{report_type}]")
        return True  # éƒ¨åˆ†æˆåŠŸä¹Ÿè§†ä¸ºæˆåŠŸ
    else:
        print(f"{log_prefix}å‘é€å®Œå…¨å¤±è´¥ [{report_type}]")
        return False


def send_to_bark(
    bark_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
) -> bool:
    """å‘é€åˆ°Barkï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä½¿ç”¨ markdown æ ¼å¼ï¼‰"""
    # æ—¥å¿—å‰ç¼€
    log_prefix = f"Bark{account_label}" if account_label else "Bark"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è§£æ Bark URLï¼Œæå– device_key å’Œ API ç«¯ç‚¹
    # Bark URL æ ¼å¼: https://api.day.app/device_key æˆ– https://bark.day.app/device_key
    from urllib.parse import urlparse

    parsed_url = urlparse(bark_url)
    device_key = parsed_url.path.strip('/').split('/')[0] if parsed_url.path else None

    if not device_key:
        print(f"{log_prefix} URL æ ¼å¼é”™è¯¯ï¼Œæ— æ³•æå– device_key: {bark_url}")
        return False

    # æ„å»ºæ­£ç¡®çš„ API ç«¯ç‚¹
    api_endpoint = f"{parsed_url.scheme}://{parsed_url.netloc}/push"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼ˆBark é™åˆ¶ä¸º 3600 å­—èŠ‚ä»¥é¿å… 413 é”™è¯¯ï¼‰ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    bark_batch_size = CONFIG["BARK_BATCH_SIZE"]
    header_reserve = _get_max_batch_header_size("bark")
    batches = split_content_into_batches(
        report_data, "bark", update_info, max_bytes=bark_batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "bark", bark_batch_size)

    total_batches = len(batches)
    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {total_batches} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # åè½¬æ‰¹æ¬¡é¡ºåºï¼Œä½¿å¾—åœ¨Barkå®¢æˆ·ç«¯æ˜¾ç¤ºæ—¶é¡ºåºæ­£ç¡®
    # Barkæ˜¾ç¤ºæœ€æ–°æ¶ˆæ¯åœ¨ä¸Šé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æœ€åä¸€æ‰¹å¼€å§‹æ¨é€
    reversed_batches = list(reversed(batches))

    print(f"{log_prefix}å°†æŒ‰åå‘é¡ºåºæ¨é€ï¼ˆæœ€åæ‰¹æ¬¡å…ˆæ¨é€ï¼‰ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ˜¾ç¤ºé¡ºåºæ­£ç¡®")

    # é€æ‰¹å‘é€ï¼ˆåå‘é¡ºåºï¼‰
    success_count = 0
    for idx, batch_content in enumerate(reversed_batches, 1):
        # è®¡ç®—æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼ˆç”¨æˆ·è§†è§’çš„ç¼–å·ï¼‰
        actual_batch_num = total_batches - idx + 1

        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡ï¼ˆæ¨é€é¡ºåº: {idx}/{total_batches}ï¼‰ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ£€æŸ¥æ¶ˆæ¯å¤§å°ï¼ˆBarkä½¿ç”¨APNsï¼Œé™åˆ¶4KBï¼‰
        if batch_size > 4096:
            print(
                f"è­¦å‘Šï¼š{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§ï¼ˆ{batch_size} å­—èŠ‚ï¼‰ï¼Œå¯èƒ½è¢«æ‹’ç»"
            )

        # æ„å»ºJSON payload
        payload = {
            "title": report_type,
            "markdown": batch_content,
            "device_key": device_key,
            "sound": "default",
            "group": "TrendRadar",
            "action": "none",  # ç‚¹å‡»æ¨é€è·³åˆ° APP ä¸å¼¹å‡ºå¼¹æ¡†,æ–¹ä¾¿é˜…è¯»
        }

        try:
            response = requests.post(
                api_endpoint,
                json=payload,
                proxies=proxies,
                timeout=30,
            )

            if response.status_code == 200:
                result = response.json()
                if result.get("code") == 200:
                    print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    success_count += 1
                    # æ‰¹æ¬¡é—´é—´éš”
                    if idx < total_batches:
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                    )
            else:
                print(
                    f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                try:
                    print(f"é”™è¯¯è¯¦æƒ…ï¼š{response.text}")
                except:
                    pass

        except requests.exceptions.ConnectTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ReadTimeout:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¯»å–è¶…æ—¶ [{report_type}]")
        except requests.exceptions.ConnectionError as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥é”™è¯¯ [{report_type}]ï¼š{e}")
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¼‚å¸¸ [{report_type}]ï¼š{e}")

    # åˆ¤æ–­æ•´ä½“å‘é€æ˜¯å¦æˆåŠŸ
    if success_count == total_batches:
        print(f"{log_prefix}æ‰€æœ‰ {total_batches} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
        return True
    elif success_count > 0:
        print(f"{log_prefix}éƒ¨åˆ†å‘é€æˆåŠŸï¼š{success_count}/{total_batches} æ‰¹æ¬¡ [{report_type}]")
        return True  # éƒ¨åˆ†æˆåŠŸä¹Ÿè§†ä¸ºæˆåŠŸ
    else:
        print(f"{log_prefix}å‘é€å®Œå…¨å¤±è´¥ [{report_type}]")
        return False


def convert_markdown_to_mrkdwn(content: str) -> str:
    """
    å°†æ ‡å‡† Markdown è½¬æ¢ä¸º Slack çš„ mrkdwn æ ¼å¼

    è½¬æ¢è§„åˆ™ï¼š
    - **ç²—ä½“** â†’ *ç²—ä½“*
    - [æ–‡æœ¬](url) â†’ <url|æ–‡æœ¬>
    - ä¿ç•™å…¶ä»–æ ¼å¼ï¼ˆä»£ç å—ã€åˆ—è¡¨ç­‰ï¼‰
    """
    # 1. è½¬æ¢é“¾æ¥æ ¼å¼: [æ–‡æœ¬](url) â†’ <url|æ–‡æœ¬>
    content = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'<\2|\1>', content)

    # 2. è½¬æ¢ç²—ä½“: **æ–‡æœ¬** â†’ *æ–‡æœ¬*
    content = re.sub(r'\*\*([^*]+)\*\*', r'*\1*', content)

    return content


def send_to_slack(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    account_label: str = "",
) -> bool:
    """å‘é€åˆ°Slack(æ”¯æŒåˆ†æ‰¹å‘é€,ä½¿ç”¨ mrkdwn æ ¼å¼ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # æ—¥å¿—å‰ç¼€
    log_prefix = f"Slack{account_label}" if account_label else "Slack"

    # è·å–åˆ†æ‰¹å†…å®¹ï¼ˆä½¿ç”¨ Slack æ‰¹æ¬¡å¤§å°ï¼‰ï¼Œé¢„ç•™æ‰¹æ¬¡å¤´éƒ¨ç©ºé—´
    slack_batch_size = CONFIG["SLACK_BATCH_SIZE"]
    header_reserve = _get_max_batch_header_size("slack")
    batches = split_content_into_batches(
        report_data, "slack", update_info, max_bytes=slack_batch_size - header_reserve, mode=mode
    )

    # ç»Ÿä¸€æ·»åŠ æ‰¹æ¬¡å¤´éƒ¨ï¼ˆå·²é¢„ç•™ç©ºé—´ï¼Œä¸ä¼šè¶…é™ï¼‰
    batches = add_batch_headers(batches, "slack", slack_batch_size)

    print(f"{log_prefix}æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        # è½¬æ¢ Markdown åˆ° mrkdwn æ ¼å¼
        mrkdwn_content = convert_markdown_to_mrkdwn(batch_content)

        batch_size = len(mrkdwn_content.encode("utf-8"))
        print(
            f"å‘é€{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ„å»º Slack payloadï¼ˆä½¿ç”¨ç®€å•çš„ text å­—æ®µï¼Œæ”¯æŒ mrkdwnï¼‰
        payload = {
            "text": mrkdwn_content
        }

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )

            # Slack Incoming Webhooks æˆåŠŸæ—¶è¿”å› "ok" æ–‡æœ¬
            if response.status_code == 200 and response.text == "ok":
                print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                # æ‰¹æ¬¡é—´é—´éš”
                if i < len(batches):
                    time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
            else:
                error_msg = response.text if response.text else f"çŠ¶æ€ç ï¼š{response.status_code}"
                print(
                    f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{error_msg}"
                )
                return False
        except Exception as e:
            print(f"{log_prefix}ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"{log_prefix}æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True
